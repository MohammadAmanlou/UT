{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCkCZGEc4Zrk"
      },
      "source": [
        "# 🤖 AI, CA3, Machine Learning 📚  \n",
        "\n",
        "* **Name** : [Enter your name] 🖊  \n",
        "* **Last Name** : [Enter your last name] 📝  \n",
        "* **SID** : [Enter your SID] 🆔"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmGZXrlo4Zrn"
      },
      "source": [
        "## 🧹 Data Preprocessing  \n",
        "Implement all your preprocessing in this section, following the guidelines provided in the project documentation 📄.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNvfvgkI4Zro"
      },
      "source": [
        "### 📥 Load Dataset  \n",
        "In this subsection, you should load the dataset as a pandas dataframe 🐼."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIw0lS354Zro"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFQY0Txh4Zrp"
      },
      "source": [
        "### ➕ Additional Columns  \n",
        "In this subsection, you should add some additional columns to the dataframe, according to the project documentation 📄."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q26S1bkO4Zrq"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgn6szua4Zrq"
      },
      "source": [
        "### 🧩 Manipulate Columns 🔢  \n",
        "In this subsection, you should extract numerical values from columns and also convert categorical data to numerical values,as described in the project documentation 📄."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJkox5NA4Zrr"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTxWLaRJ4Zrr"
      },
      "source": [
        "### 🛠 Handling Missing Values 💡\n",
        "In this subsection, you are supposed to handle null and missing values, following regular techinuques, used in this context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GaWOfG14Zrs"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_yzIbjf4Zrs"
      },
      "source": [
        "### 🏷 Assigning Labels  \n",
        "In this subsection, we want to assign labels to hotels 🏨, according to their price 💰.  \n",
        "We have two labels:  \n",
        "- **0** for hotels with a price less than a threshold 🟢.  \n",
        "- **1** for those with higher prices 🔴.  \n",
        "\n",
        "To determine the threshold, we use the median of prices 📊.  \n",
        "In the first step, complete the following function. Then, you should use the `apply` method of pandas 🐼 to assign labels to each hotel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77iioqNu4Zrs"
      },
      "outputs": [],
      "source": [
        "def assign_label(x, column):\n",
        "    \"\"\"\n",
        "        x:price(int),\n",
        "        column:\"price\"(str),\n",
        "        returns label of x as explained\n",
        "    \"\"\"\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0gw22Mx4Zrt"
      },
      "source": [
        "## 📊 Data Visualization  \n",
        "Research and explore various data visualization techniques 🔍 to identify the best options for your project 🎯. Different approaches may be suitable for different aspects of your data 📈."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I0uWFQO4Zrt"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLe_ZTYl4Zrt"
      },
      "source": [
        "## 🏷 Classification  \n",
        "In this section, we will go through the classification pipeline. We will deploy several machine learning models to classify hotels based on their price 💵. Finally, you will implement a boosting algorithm from scratch 🛠 and compare its performance with the library implementation 📚."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4pcK7rF4Zrt"
      },
      "source": [
        "### 🔀 Train-Test Split  \n",
        "You should divide the data into a training set and a test set. Use 20% of the data for testing and 80% for training 📊."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX4jNVVo4Zrt"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wob2QqB54Zrt"
      },
      "source": [
        "### 🌐 Normalization  \n",
        "One of the most important steps in the classification pipeline is normalization. You will be asked about the importance of this step ⚙️."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlw0ZRhF4Zru"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_FOXIQp4Zru"
      },
      "source": [
        "### 🚀 Deploying Sklearn Models  \n",
        "In this subsection, you should use built-in models from the sklearn library for the classification task. Don't forget to show the complete classification report, including the confusion matrix, precision, recall, F1-score, and accuracy 📊. You will be asked about these metrics 📈."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWEFZgBI4Zru"
      },
      "source": [
        "#### 📉 Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLx0W19r4Zru"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozKArDaG4Zru"
      },
      "source": [
        "#### 🌳 Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvcHxVbf4Zru"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGffcVZM4Zru"
      },
      "source": [
        "#### 🌲🌳 Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLujg_S74Zrv"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBRuC-X74Zrv"
      },
      "source": [
        "#### ⚡️ Adaptive Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjsApxuj4Zrv"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NIwubFz4Zrw"
      },
      "source": [
        "#### ⚡️ XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nQg6EGd4Zrw"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16W9o1DZ4Zrw"
      },
      "source": [
        "### 🛠 From Scratch  \n",
        "In this subsection, you should implement the SAMME algorithm for adaptive boosting from scratch.Then you should deploy this boosting model and a base estimator, which is Gaussian Naive Bayes here, to classify hotels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKpw7X4o4Zrw"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "class SimpleMultiClassBoosting(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, base_estimator=GaussianNB, n_estimators=50):\n",
        "        self.base_estimator = base_estimator if base_estimator is not None else GaussianNB()\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learners = []\n",
        "        self.learner_weights = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples = X.shape[0]\n",
        "        self.weights = (1/n_samples) * np.ones(n_samples, dtype=float) # initialize weights uniformly\n",
        "        for _ in range(self.n_estimators):\n",
        "            learner = GaussianNB() # instanciate model\n",
        "            learner.fit(X, y, sample_weight=self.weights) # fit to samples, using weights\n",
        "            pred = learner.predict(X) # predict the batch\n",
        "            missClassified = pred != y # get index of misclassified samples\n",
        "            # TODO : compute learner error rate according to SAMME algorithm\n",
        "            # TODO : compute learner weight using SAMME algorithm\n",
        "            # TODO : a classifier with error rate which is worse than random should be dropped\n",
        "            # hint : error rate of untrained classifier : 1 - (1 / n_classes)\n",
        "\n",
        "            # TODO : increase the weights of misclassified samples according to SAMME algorithm\n",
        "            self.weights /= np.sum(self.weights) # renormalize weights to make them sum up to 1\n",
        "            self.learners.append(learner)\n",
        "            # TODO : store learner weight in self.learner_weights\n",
        "\n",
        "    def predict(self, X):\n",
        "        # note that X can contain multiple samples in shape of array, in which, each row corresponds to a query\n",
        "        predictionsOfLearners = []\n",
        "        for learner in self.learners:\n",
        "            predictionsOfLearners.append(learner.predict(X)) # collect predictions from each learner\n",
        "        # TODO : weighted vote for each sample's prediction across all learners, each learner's weight is stored in self.learner_weights\n",
        "        # TODO : make final prediction by considering the label which has highest weighted vote\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}