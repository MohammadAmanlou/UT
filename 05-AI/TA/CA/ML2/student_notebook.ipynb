{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCkCZGEc4Zrk"
      },
      "source": [
        "# ü§ñ AI, CA3, Machine Learning üìö  \n",
        "\n",
        "* **Name** : [Enter your name] üñä  \n",
        "* **Last Name** : [Enter your last name] üìù  \n",
        "* **SID** : [Enter your SID] üÜî"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmGZXrlo4Zrn"
      },
      "source": [
        "## üßπ Data Preprocessing  \n",
        "Implement all your preprocessing in this section, following the guidelines provided in the project documentation üìÑ.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNvfvgkI4Zro"
      },
      "source": [
        "### üì• Load Dataset  \n",
        "In this subsection, you should load the dataset as a pandas dataframe üêº."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIw0lS354Zro"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFQY0Txh4Zrp"
      },
      "source": [
        "### ‚ûï Additional Columns  \n",
        "In this subsection, you should add some additional columns to the dataframe, according to the project documentation üìÑ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q26S1bkO4Zrq"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgn6szua4Zrq"
      },
      "source": [
        "### üß© Manipulate Columns üî¢  \n",
        "In this subsection, you should extract numerical values from columns and also convert categorical data to numerical values,as described in the project documentation üìÑ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJkox5NA4Zrr"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTxWLaRJ4Zrr"
      },
      "source": [
        "### üõ† Handling Missing Values üí°\n",
        "In this subsection, you are supposed to handle null and missing values, following regular techinuques, used in this context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GaWOfG14Zrs"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_yzIbjf4Zrs"
      },
      "source": [
        "### üè∑ Assigning Labels  \n",
        "In this subsection, we want to assign labels to hotels üè®, according to their price üí∞.  \n",
        "We have two labels:  \n",
        "- **0** for hotels with a price less than a threshold üü¢.  \n",
        "- **1** for those with higher prices üî¥.  \n",
        "\n",
        "To determine the threshold, we use the median of prices üìä.  \n",
        "In the first step, complete the following function. Then, you should use the `apply` method of pandas üêº to assign labels to each hotel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77iioqNu4Zrs"
      },
      "outputs": [],
      "source": [
        "def assign_label(x, column):\n",
        "    \"\"\"\n",
        "        x:price(int),\n",
        "        column:\"price\"(str),\n",
        "        returns label of x as explained\n",
        "    \"\"\"\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0gw22Mx4Zrt"
      },
      "source": [
        "## üìä Data Visualization  \n",
        "Research and explore various data visualization techniques üîç to identify the best options for your project üéØ. Different approaches may be suitable for different aspects of your data üìà."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I0uWFQO4Zrt"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLe_ZTYl4Zrt"
      },
      "source": [
        "## üè∑ Classification  \n",
        "In this section, we will go through the classification pipeline. We will deploy several machine learning models to classify hotels based on their price üíµ. Finally, you will implement a boosting algorithm from scratch üõ† and compare its performance with the library implementation üìö."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4pcK7rF4Zrt"
      },
      "source": [
        "### üîÄ Train-Test Split  \n",
        "You should divide the data into a training set and a test set. Use 20% of the data for testing and 80% for training üìä."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX4jNVVo4Zrt"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wob2QqB54Zrt"
      },
      "source": [
        "### üåê Normalization  \n",
        "One of the most important steps in the classification pipeline is normalization. You will be asked about the importance of this step ‚öôÔ∏è."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlw0ZRhF4Zru"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_FOXIQp4Zru"
      },
      "source": [
        "### üöÄ Deploying Sklearn Models  \n",
        "In this subsection, you should use built-in models from the sklearn library for the classification task. Don't forget to show the complete classification report, including the confusion matrix, precision, recall, F1-score, and accuracy üìä. You will be asked about these metrics üìà."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWEFZgBI4Zru"
      },
      "source": [
        "#### üìâ Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLx0W19r4Zru"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozKArDaG4Zru"
      },
      "source": [
        "#### üå≥ Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvcHxVbf4Zru"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGffcVZM4Zru"
      },
      "source": [
        "#### üå≤üå≥ Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLujg_S74Zrv"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBRuC-X74Zrv"
      },
      "source": [
        "#### ‚ö°Ô∏è Adaptive Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjsApxuj4Zrv"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NIwubFz4Zrw"
      },
      "source": [
        "#### ‚ö°Ô∏è XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nQg6EGd4Zrw"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16W9o1DZ4Zrw"
      },
      "source": [
        "### üõ† From Scratch  \n",
        "In this subsection, you should implement the SAMME algorithm for adaptive boosting from scratch.Then you should deploy this boosting model and a base estimator, which is Gaussian Naive Bayes here, to classify hotels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKpw7X4o4Zrw"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "class SimpleMultiClassBoosting(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, base_estimator=GaussianNB, n_estimators=50):\n",
        "        self.base_estimator = base_estimator if base_estimator is not None else GaussianNB()\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learners = []\n",
        "        self.learner_weights = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples = X.shape[0]\n",
        "        self.weights = (1/n_samples) * np.ones(n_samples, dtype=float) # initialize weights uniformly\n",
        "        for _ in range(self.n_estimators):\n",
        "            learner = GaussianNB() # instanciate model\n",
        "            learner.fit(X, y, sample_weight=self.weights) # fit to samples, using weights\n",
        "            pred = learner.predict(X) # predict the batch\n",
        "            missClassified = pred != y # get index of misclassified samples\n",
        "            # TODO : compute learner error rate according to SAMME algorithm\n",
        "            # TODO : compute learner weight using SAMME algorithm\n",
        "            # TODO : a classifier with error rate which is worse than random should be dropped\n",
        "            # hint : error rate of untrained classifier : 1 - (1 / n_classes)\n",
        "\n",
        "            # TODO : increase the weights of misclassified samples according to SAMME algorithm\n",
        "            self.weights /= np.sum(self.weights) # renormalize weights to make them sum up to 1\n",
        "            self.learners.append(learner)\n",
        "            # TODO : store learner weight in self.learner_weights\n",
        "\n",
        "    def predict(self, X):\n",
        "        # note that X can contain multiple samples in shape of array, in which, each row corresponds to a query\n",
        "        predictionsOfLearners = []\n",
        "        for learner in self.learners:\n",
        "            predictionsOfLearners.append(learner.predict(X)) # collect predictions from each learner\n",
        "        # TODO : weighted vote for each sample's prediction across all learners, each learner's weight is stored in self.learner_weights\n",
        "        # TODO : make final prediction by considering the label which has highest weighted vote\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}